{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Mount Drive (if using Google Drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# STEP 2: Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# STEP 3: Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# STEP 4: Set Paths and Hyperparameters\n",
        "data_dir = \"/content/drive/MyDrive/dataset\"\n",
        "BATCH_SIZE = 16\n",
        "IMG_SIZE = 128\n",
        "EPOCHS = 50\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# STEP 5: Data Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# STEP 6: Datasets and Dataloaders\n",
        "full_dataset = datasets.ImageFolder(data_dir)\n",
        "class_names = full_dataset.classes\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "# Split manually into 80-20\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataset.dataset.transform = train_transform\n",
        "val_dataset.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# STEP 7: Define CNN Model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * (IMG_SIZE // 8) * (IMG_SIZE // 8), 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = CNNModel(num_classes=len(class_names)).to(device)\n",
        "\n",
        "# STEP 8: Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# STEP 9: Training Loop with Best Model Saving\n",
        "best_acc = 0.0\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = val_correct / val_total\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/best_animal_model.pth\")\n",
        "        print(\"✅ Best model saved\")\n",
        "\n",
        "# STEP 10: Evaluation\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/best_animal_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UdesQXpxIEF",
        "outputId": "5ed16d44-6ccd-4dda-b888-e0979965c228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Classes: ['Bear', 'Bird', 'Cat', 'Cow', 'Deer', 'Dog', 'Dolphin', 'Elephant', 'Giraffe', 'Horse', 'Kangaroo', 'Lion', 'Panda', 'Tiger', 'Zebra']\n",
            "Epoch 1/50 | Train Acc: 0.1055 | Val Acc: 0.1568\n",
            "✅ Best model saved\n",
            "Epoch 2/50 | Train Acc: 0.1601 | Val Acc: 0.1928\n",
            "✅ Best model saved\n",
            "Epoch 3/50 | Train Acc: 0.2039 | Val Acc: 0.2108\n",
            "✅ Best model saved\n",
            "Epoch 4/50 | Train Acc: 0.2360 | Val Acc: 0.2545\n",
            "✅ Best model saved\n",
            "Epoch 5/50 | Train Acc: 0.2920 | Val Acc: 0.3111\n",
            "✅ Best model saved\n",
            "Epoch 6/50 | Train Acc: 0.3659 | Val Acc: 0.3753\n",
            "✅ Best model saved\n",
            "Epoch 7/50 | Train Acc: 0.4469 | Val Acc: 0.4036\n",
            "✅ Best model saved\n",
            "Epoch 8/50 | Train Acc: 0.5029 | Val Acc: 0.4473\n",
            "✅ Best model saved\n",
            "Epoch 9/50 | Train Acc: 0.5762 | Val Acc: 0.5013\n",
            "✅ Best model saved\n",
            "Epoch 10/50 | Train Acc: 0.6373 | Val Acc: 0.5501\n",
            "✅ Best model saved\n",
            "Epoch 11/50 | Train Acc: 0.6746 | Val Acc: 0.5604\n",
            "✅ Best model saved\n",
            "Epoch 12/50 | Train Acc: 0.7042 | Val Acc: 0.5578\n",
            "Epoch 13/50 | Train Acc: 0.7273 | Val Acc: 0.5604\n",
            "Epoch 14/50 | Train Acc: 0.7453 | Val Acc: 0.5758\n",
            "✅ Best model saved\n",
            "Epoch 15/50 | Train Acc: 0.7794 | Val Acc: 0.6375\n",
            "✅ Best model saved\n",
            "Epoch 16/50 | Train Acc: 0.7884 | Val Acc: 0.6144\n",
            "Epoch 17/50 | Train Acc: 0.7929 | Val Acc: 0.6170\n",
            "Epoch 18/50 | Train Acc: 0.8302 | Val Acc: 0.6221\n",
            "Epoch 19/50 | Train Acc: 0.8186 | Val Acc: 0.6761\n",
            "✅ Best model saved\n",
            "Epoch 20/50 | Train Acc: 0.8495 | Val Acc: 0.6015\n",
            "Epoch 21/50 | Train Acc: 0.8309 | Val Acc: 0.6889\n",
            "✅ Best model saved\n",
            "Epoch 22/50 | Train Acc: 0.8617 | Val Acc: 0.6735\n",
            "Epoch 23/50 | Train Acc: 0.8637 | Val Acc: 0.6838\n",
            "Epoch 24/50 | Train Acc: 0.8913 | Val Acc: 0.6812\n",
            "Epoch 25/50 | Train Acc: 0.7768 | Val Acc: 0.5913\n",
            "Epoch 26/50 | Train Acc: 0.8469 | Val Acc: 0.6967\n",
            "✅ Best model saved\n",
            "Epoch 27/50 | Train Acc: 0.8707 | Val Acc: 0.7249\n",
            "✅ Best model saved\n",
            "Epoch 28/50 | Train Acc: 0.9055 | Val Acc: 0.7249\n",
            "Epoch 29/50 | Train Acc: 0.8945 | Val Acc: 0.7121\n",
            "Epoch 30/50 | Train Acc: 0.9203 | Val Acc: 0.6967\n",
            "Epoch 31/50 | Train Acc: 0.9293 | Val Acc: 0.7301\n",
            "✅ Best model saved\n",
            "Epoch 32/50 | Train Acc: 0.9235 | Val Acc: 0.7404\n",
            "✅ Best model saved\n",
            "Epoch 33/50 | Train Acc: 0.9215 | Val Acc: 0.7147\n",
            "Epoch 34/50 | Train Acc: 0.9453 | Val Acc: 0.7044\n",
            "Epoch 35/50 | Train Acc: 0.9357 | Val Acc: 0.7352\n",
            "Epoch 36/50 | Train Acc: 0.9383 | Val Acc: 0.7429\n",
            "✅ Best model saved\n",
            "Epoch 37/50 | Train Acc: 0.9421 | Val Acc: 0.6761\n",
            "Epoch 38/50 | Train Acc: 0.9408 | Val Acc: 0.7044\n",
            "Epoch 39/50 | Train Acc: 0.9473 | Val Acc: 0.6838\n",
            "Epoch 40/50 | Train Acc: 0.9447 | Val Acc: 0.7095\n",
            "Epoch 41/50 | Train Acc: 0.9537 | Val Acc: 0.7018\n",
            "Epoch 42/50 | Train Acc: 0.9453 | Val Acc: 0.7147\n",
            "Epoch 43/50 | Train Acc: 0.9614 | Val Acc: 0.7301\n",
            "Epoch 44/50 | Train Acc: 0.9434 | Val Acc: 0.7095\n",
            "Epoch 45/50 | Train Acc: 0.9460 | Val Acc: 0.7147\n",
            "Epoch 46/50 | Train Acc: 0.9511 | Val Acc: 0.7018\n",
            "Epoch 47/50 | Train Acc: 0.9511 | Val Acc: 0.7095\n",
            "Epoch 48/50 | Train Acc: 0.9614 | Val Acc: 0.7147\n",
            "Epoch 49/50 | Train Acc: 0.9486 | Val Acc: 0.7326\n",
            "Epoch 50/50 | Train Acc: 0.9627 | Val Acc: 0.7326\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Bear       0.78      0.96      0.86        26\n",
            "        Bird       0.75      0.69      0.72        26\n",
            "         Cat       0.67      0.67      0.67        18\n",
            "         Cow       0.86      0.56      0.68        34\n",
            "        Deer       0.65      0.81      0.72        21\n",
            "         Dog       0.71      0.65      0.68        23\n",
            "     Dolphin       1.00      0.94      0.97        32\n",
            "    Elephant       0.67      0.62      0.64        26\n",
            "     Giraffe       0.56      0.77      0.65        26\n",
            "       Horse       0.79      0.56      0.65        27\n",
            "    Kangaroo       0.55      0.81      0.66        26\n",
            "        Lion       0.81      0.57      0.67        30\n",
            "       Panda       0.83      1.00      0.91        29\n",
            "       Tiger       0.79      0.65      0.71        23\n",
            "       Zebra       0.83      0.91      0.87        22\n",
            "\n",
            "    accuracy                           0.74       389\n",
            "   macro avg       0.75      0.74      0.74       389\n",
            "weighted avg       0.76      0.74      0.74       389\n",
            "\n",
            "Confusion Matrix:\n",
            "[[25  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 18  1  0  0  0  0  0  0  0  4  1  2  0  0]\n",
            " [ 0  1 12  0  0  1  0  1  1  0  2  0  0  0  0]\n",
            " [ 0  1  1 19  4  1  0  2  2  0  1  2  0  1  0]\n",
            " [ 0  0  0  0 17  0  0  0  1  0  1  0  1  0  1]\n",
            " [ 0  0  2  0  0 15  0  0  2  0  1  0  1  1  1]\n",
            " [ 1  0  0  0  0  0 30  0  0  0  0  0  1  0  0]\n",
            " [ 4  0  1  0  0  0  0 16  3  0  1  0  1  0  0]\n",
            " [ 0  1  0  0  0  1  0  2 20  2  0  0  0  0  0]\n",
            " [ 0  3  0  0  1  0  0  1  4 15  1  1  0  0  1]\n",
            " [ 2  0  0  0  1  0  0  0  1  1 21  0  0  0  0]\n",
            " [ 0  0  0  1  2  1  0  0  2  1  5 17  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 29  0  0]\n",
            " [ 0  0  1  1  1  2  0  1  0  0  1  0  0 15  1]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  1 20]]\n"
          ]
        }
      ]
    }
  ]
}